# YoloKeras-Detection

This project was developed by Ant√≥nio Pedro Silva Matos for object detection using the YOLO (You Only Look Once) and Keras (TensorFLow) models. The goal is to provide a unified platform to explore, test, and compare the performance of these models across diverse datasets and scenarios.

## Summary

1. [**Introduction**](#introduction)
2. [**Overview**](#overview)
3. [**Functionalities**](#functionalities)
4. [**Configuration**](#configuration)
5. [**Requirements**](#requirements)
6. [**Configuration**](#configuration)
7. [**Preperation**](#preperation)
   - [**Download**](#download)
   - [**Installation**](#installation)
8. [**Contribution**](#contribution)
9. [**License**](#license)

## Introduction

This repository presents an innovative platform for object detection, combining two of the most advanced models in the field: YOLO and Keras. Developed to provide a detailed comparison between the two approaches, the project aims to help researchers and developers explore and evaluate the effectiveness of each model in diverse scenarios.

## Contribution

Feel free to open issues and submit pull requests. Contributions are welcome!

We consider exploring the Darknet YOLO ecosystem for valuable insights and testing different dataset versions and models. Our goal is to improve object detection using the official [Darknet repository](https://github.com/AlexeyAB/darknet). We plan to create a personalized dataset with relevant objects to improve the mobility of the visually impaired, aiming to significantly increase detection accuracy.

For this code we utilize a flexx2 depth camera from [Pmdtec](https://3d.pmdtec.com/en/3d-cameras/flexx2/)

# License

YoloKeras-Detection itself is released under the MIT License (refer to the LICENSE file for details). Portions of the code are borrowed and given by [pmdtechnologies](https://github.com/pmdtechnologies/SampleYOLO) and from their [RoyaleSDK](https://pmdtec.com/en/download-sdk/)
